{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Happy Moments Using Char-RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Char-RNN implements multi-layer Recurrent Neural Network (RNN, LSTM, and GRU) for training/sampling from character-level language models. In other words the model takes one text file as input and trains a Recurrent Neural Network that learns to predict the next character in a sequence. The RNN can then be used to generate text character by character that will look like the original training data. This network is first posted by Andrej Karpathy, you can find out about his original code on https://github.com/karpathy/char-rnn, the original code is written in *lua*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import re\n",
    "# Notebook auto reloads code. (Ref: http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "In this part, we will use only the cleaned hm data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hmid</th>\n",
       "      <th>wid</th>\n",
       "      <th>reflection_period</th>\n",
       "      <th>original_hm</th>\n",
       "      <th>cleaned_hm</th>\n",
       "      <th>modified</th>\n",
       "      <th>num_sentence</th>\n",
       "      <th>ground_truth_category</th>\n",
       "      <th>predicted_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27673</td>\n",
       "      <td>2053</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went on a successful date with someone I fel...</td>\n",
       "      <td>I went on a successful date with someone I fel...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27674</td>\n",
       "      <td>2</td>\n",
       "      <td>24h</td>\n",
       "      <td>I was happy when my son got 90% marks in his e...</td>\n",
       "      <td>I was happy when my son got 90% marks in his e...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27675</td>\n",
       "      <td>1936</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went to the gym this morning and did yoga.</td>\n",
       "      <td>I went to the gym this morning and did yoga.</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>exercise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27676</td>\n",
       "      <td>206</td>\n",
       "      <td>24h</td>\n",
       "      <td>We had a serious talk with some friends of our...</td>\n",
       "      <td>We had a serious talk with some friends of our...</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>bonding</td>\n",
       "      <td>bonding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27677</td>\n",
       "      <td>6227</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went with grandchildren to butterfly display...</td>\n",
       "      <td>I went with grandchildren to butterfly display...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hmid   wid reflection_period  \\\n",
       "0  27673  2053               24h   \n",
       "1  27674     2               24h   \n",
       "2  27675  1936               24h   \n",
       "3  27676   206               24h   \n",
       "4  27677  6227               24h   \n",
       "\n",
       "                                         original_hm  \\\n",
       "0  I went on a successful date with someone I fel...   \n",
       "1  I was happy when my son got 90% marks in his e...   \n",
       "2       I went to the gym this morning and did yoga.   \n",
       "3  We had a serious talk with some friends of our...   \n",
       "4  I went with grandchildren to butterfly display...   \n",
       "\n",
       "                                          cleaned_hm  modified  num_sentence  \\\n",
       "0  I went on a successful date with someone I fel...      True             1   \n",
       "1  I was happy when my son got 90% marks in his e...      True             1   \n",
       "2       I went to the gym this morning and did yoga.      True             1   \n",
       "3  We had a serious talk with some friends of our...      True             2   \n",
       "4  I went with grandchildren to butterfly display...      True             1   \n",
       "\n",
       "  ground_truth_category predicted_category  \n",
       "0                   NaN          affection  \n",
       "1                   NaN          affection  \n",
       "2                   NaN           exercise  \n",
       "3               bonding            bonding  \n",
       "4                   NaN          affection  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/cleaned_hm.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 9460832 characters\n",
      "I went on a successful date with someone I felt sympathy and connection with. I was happy when my son got 90% marks in his examination  I went to the gym this morning and did yoga. We had a serious talk with some friends of ours who have been flaky lately. They understood and we had a good evening hanging out. I went with grandchildren to butterfly display at Crohn Conservatory\r\n",
      " I meditated last night. I made a new recipe for peasant bread, and it came out spectacular! I got gift from my elder \n"
     ]
    }
   ],
   "source": [
    "text = \" \".join([words for words in data[\"cleaned_hm\"]])\n",
    "# length of text is the number of characters in it\n",
    "print('Length of text: {} characters'.format(len(text)))\n",
    "# and let's get a glance of what the text is\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to strip all the weird extra characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\t'   --->    0\n",
      "'\\n'   --->    1\n",
      "'\\r'   --->    2\n",
      "' '    --->    3\n",
      "'!'    --->    4\n",
      "'\"'    --->    5\n",
      "'#'    --->    6\n",
      "'$'    --->    7\n",
      "'%'    --->    8\n",
      "'&'    --->    9\n",
      "\"'\"    --->   10\n",
      "'('    --->   11\n",
      "')'    --->   12\n",
      "'*'    --->   13\n",
      "'+'    --->   14\n",
      "','    --->   15\n",
      "'-'    --->   16\n",
      "'.'    --->   17\n",
      "'/'    --->   18\n",
      "'0'    --->   19\n",
      "I went on  --- characters mapped to int --- > [44  3 89 71 80 86  3 81 80  3]\n"
     ]
    }
   ],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "vocab_to_ind = {c: i for i, c in enumerate(vocab)}\n",
    "ind_to_vocab = dict(enumerate(vocab))\n",
    "text_as_int = np.array([vocab_to_ind[c] for c in text], dtype=np.int32)\n",
    "\n",
    "# We mapped the character as indexes from 0 to len(vocab)\n",
    "for char,_ in zip(vocab_to_ind, range(20)):\n",
    "    print('{:6s} ---> {:4d}'.format(repr(char), vocab_to_ind[char]))\n",
    "# Show how the first 10 characters from the text are mapped to integers\n",
    "print ('{} --- characters mapped to int --- > {}'.format(text[:10], text_as_int[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Batches Using Generators\n",
    "We're going to partition our data\n",
    "\n",
    "1. **batch_size**: Reviewing batches in CNN, if we have 100 samples and we set batch_size as 10, it means that we will send 10 samples to the network at one time. In RNN, batch_size have the same meaning, it defines how many samples we send to the network at one time.\n",
    "2. **sequence_length**: However, as for RNN, we store memory in our cells, we pass the information through cells, so we have this sequence_length concept, which also called 'steps', it defines how long a sequence is.\n",
    "\n",
    "From above two concepts, we here clarify the meaning of batch_size in RNN. Here, we define the number of sequences in a batch as N and the length of each sequence as M, so batch_size in RNN **still** represent the number of sequences in a batch but the data size of a batch is actually an array of size **[N, M]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(array, n_seqs, n_steps):\n",
    "    '''\n",
    "    Partition data array into mini-batches\n",
    "    input:\n",
    "    array: input data\n",
    "    n_seqs: number of sequences in a batch N\n",
    "    n_steps: length of each sequence  M\n",
    "    output:\n",
    "    x: inputs\n",
    "    y: targets, which is x with one position shift\n",
    "       you can check the following figure to get the sence of what a target looks like\n",
    "    '''\n",
    "    batch_size = n_seqs * n_steps\n",
    "    n_batches = int(len(array) / batch_size)\n",
    "    batch_count=0\n",
    "    # we only keep the full batches and ignore the left.\n",
    "    x = array[:batch_size * n_batches]\n",
    "    y = array[1:batch_size * n_batches +1]\n",
    "    x = x.reshape((n_seqs, -1))\n",
    "    y = y.reshape((n_seqs, -1))\n",
    "    # You should now create a loop to generate batches for inputs and targets\n",
    "\n",
    "    while True:\n",
    "        if batch_count < n_batches:\n",
    "            yield (x[:,batch_count * n_steps : (batch_count +1) * n_steps], \n",
    "                   y[:,batch_count * n_steps : (batch_count +1) * n_steps]) # yield new batch\n",
    "            batch_count += 1 # update counter\n",
    "        else:\n",
    "            batch_count = 0 # reset counter when we went through all data\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      " [[44  3 89 71 80 86  3 81 80  3]\n",
      " [67 88 81 84 75 86 71  3 85 74]\n",
      " [ 3 67  3 80 75 69 71  3 67 80]\n",
      " [ 4  3 75  3 73 81  3 86 81  3]\n",
      " [ 3 67 86  3 67  3 69 81 79 82]\n",
      " [67 86 71 84  3 85 74 71  3 89]\n",
      " [74  3 51 85 91 69 74  3 81 80]\n",
      " [71  3 74 75 79  3 67  3 85 86]\n",
      " [67 73 71 17  3 55 74 71  3 79]\n",
      " [86 74  3 79 91  3 68 71 85 86]]\n",
      "\n",
      "y\n",
      " [[ 3 89 71 80 86  3 81 80  3 67]\n",
      " [88 81 84 75 86 71  3 85 74 81]\n",
      " [67  3 80 75 69 71  3 67 80 70]\n",
      " [ 3 75  3 73 81  3 86 81  3 81]\n",
      " [67 86  3 67  3 69 81 79 82 67]\n",
      " [86 71 84  3 85 74 71  3 89 81]\n",
      " [ 3 51 85 91 69 74  3 81 80  3]\n",
      " [ 3 74 75 79  3 67  3 85 86 71]\n",
      " [73 71 17  3 55 74 71  3 79 67]\n",
      " [74  3 79 91  3 68 71 85 86  3]]\n"
     ]
    }
   ],
   "source": [
    "batches= get_batches(text_as_int, 10, 10)\n",
    "x, y = next(batches)\n",
    "print('x\\n', x[:10, :10])\n",
    "print('\\ny\\n', y[:10, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 10), (10, 10))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape , y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Char-RNN model\n",
    "We will build our char-rnn model, it consists of input layer, rnn_cell layer, output layer, loss and optimizer, we will build them one by one.\n",
    "\n",
    "The goal is to predict new text after given prime word, so for our training data, we have to define inputs and targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing CharRNN class files. Contains both LSTM and GRU cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CharRNN import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "Set sampling as False(default), we can start training the network, we automatically save checkpoints in the folder /checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are preset parameters, you can change them to get better result\n",
    "batch_size = 100         # Sequences per batch\n",
    "num_steps = 100          # Number of sequence steps per batch\n",
    "rnn_size = 256           # Size of hidden layers in rnn_cell\n",
    "num_layers = 2           # Number of hidden layers\n",
    "learning_rate = 0.005    # Learning rate\n",
    "keep_prob=0.5\n",
    "cell_type='LSTM'\n",
    "grad_clip=5\n",
    "train_keep_prob=0.5\n",
    "max_count=3000\n",
    "save_every_n=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 200  loss: 2.0953  0.2262 sec/batch\n",
      "step: 400  loss: 1.7041  0.2213 sec/batch\n",
      "step: 600  loss: 1.5366  0.2163 sec/batch\n",
      "step: 800  loss: 1.4672  0.2208 sec/batch\n",
      "step: 1000  loss: 1.4641  0.2203 sec/batch\n",
      "step: 1200  loss: 1.3372  0.2177 sec/batch\n",
      "step: 1400  loss: 1.3356  0.2187 sec/batch\n",
      "step: 1600  loss: 1.3520  0.2253 sec/batch\n",
      "step: 1800  loss: 1.3085  0.2211 sec/batch\n",
      "step: 2000  loss: 1.3172  0.2220 sec/batch\n",
      "step: 2200  loss: 1.2716  0.2161 sec/batch\n",
      "step: 2400  loss: 1.2783  0.2181 sec/batch\n",
      "step: 2600  loss: 1.2904  0.2214 sec/batch\n",
      "step: 2800  loss: 1.2654  0.2211 sec/batch\n",
      "step: 3000  loss: 1.2168  0.2184 sec/batch\n",
      "step: 3200  loss: 1.2611  0.2225 sec/batch\n",
      "step: 3400  loss: 1.2426  0.2172 sec/batch\n",
      "step: 3600  loss: 1.2458  0.2188 sec/batch\n",
      "step: 3800  loss: 1.2176  0.2215 sec/batch\n",
      "step: 4000  loss: 1.2240  0.2254 sec/batch\n",
      "step: 4200  loss: 1.2091  0.2237 sec/batch\n",
      "step: 4400  loss: 1.1978  0.2236 sec/batch\n",
      "step: 4600  loss: 1.2081  0.2197 sec/batch\n",
      "step: 4800  loss: 1.1920  0.2223 sec/batch\n",
      "step: 5000  loss: 1.1912  0.2193 sec/batch\n",
      "step: 5200  loss: 1.1844  0.2194 sec/batch\n",
      "step: 5400  loss: 1.2036  0.2212 sec/batch\n",
      "step: 5600  loss: 1.1666  0.2219 sec/batch\n",
      "step: 5800  loss: 1.1542  0.2213 sec/batch\n",
      "step: 6000  loss: 1.1863  0.2201 sec/batch\n"
     ]
    }
   ],
   "source": [
    "model = CharRNN(num_classes=len(vocab),\n",
    "                batch_size=batch_size,\n",
    "                num_steps=num_steps,\n",
    "                cell_type=cell_type, \n",
    "                rnn_size=rnn_size,\n",
    "                num_layers=num_layers,\n",
    "                learning_rate=learning_rate,\n",
    "                grad_clip=grad_clip,\n",
    "                train_keep_prob=train_keep_prob,\n",
    "                sampling=False)\n",
    "batches = get_batches(text_as_int, batch_size, num_steps)\n",
    "model.train(batches, max_count, save_every_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_checkpoint_path: \"checkpoints/i6000_l256_LSTM.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i4000_l256_LSTM.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i4500_l256_LSTM.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i5000_l256_LSTM.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i5500_l256_LSTM.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i6000_l256_LSTM.ckpt\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up checkpoints\n",
    "tf.train.get_checkpoint_state('checkpoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Make Some Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/i6000_l256_LSTM.ckpt\n",
      "My single day. My friends chicks as a trial and it starced from house, and I cound on a colference than with me and she was how and-well.  That I was supporming well for a nice milifor. I was very happy to be molling. My has so imprevie and she thought it's a feeling in along one at work and I went to my food wanting. I am selected in a few months of music, and she had been complemented about her studyed while I was a hit to see the feeds the words its satisvince in a car off. I went to bed after several open those arcoming spishes for some founday i got to gring a cell conventes of that dog which I got some tried tirlergen ticlenes after shrold and the break. I had a good time with my best friond we are able to get to be a long. I had the place. At my friend to work than any and this west man terrowing astererning to have a good discussion of a stress as the mark i asked me. I gave it to going to a present in my sister.  It was no sale in a store about the sounds.  I am a few hours on the\n"
     ]
    }
   ],
   "source": [
    "model = CharRNN(num_classes=len(vocab),\n",
    "                batch_size=batch_size,\n",
    "                num_steps=num_steps,\n",
    "                cell_type=cell_type, \n",
    "                rnn_size=rnn_size,\n",
    "                num_layers=num_layers,\n",
    "                learning_rate=learning_rate,\n",
    "                grad_clip=grad_clip,\n",
    "                train_keep_prob=train_keep_prob,\n",
    "                sampling=True)\n",
    "# choose the last checkpoint and generate new text\n",
    "checkpoint = tf.train.latest_checkpoint('checkpoints')\n",
    "samp = model.sample(checkpoint, 1000, len(vocab), vocab_to_ind, ind_to_vocab, prime=\"My \")\n",
    "print(samp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It definitely learned the structure. The 1000th iteration was much more gibberish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/i6000_l256_LSTM.ckpt\n",
      "I'm has a tempore.\n",
      " My friends and I mnt taught until that ware also selecting was a lot of free of thinks to management that I wanted in a few days!.. I goita with my friends to see my glan app on a chance to that was able to see it friends.  My friend gett our big project as well and they were happy is a standing bestie stains and I was abreaved where it was a high couch and so we was able to finish my car and I have toding twe we we sundanged, still are a few friends from my boyfriend and money with my favorite back and I hadn't hit my home and I saw me a log that I was. We ate a boss and shipent that I wanted.\n",
      "This morning my be a boour. I had seag with a new place of happy mother and hang out to the food was this the a macriay, I headed troughing out. My sister steak a surprise at that time.  My stare won my both and hot a task wish show.'I started from a concept and so that I wanted for months. This morning, the mamerhas helped to speak to suppliss.  I was happy when making me and t\n"
     ]
    }
   ],
   "source": [
    "samp = model.sample(\"checkpoints/i6000_l256_LSTM.ckpt\", 1000, len(vocab), vocab_to_ind, ind_to_vocab, prime=\"I'm \")\n",
    "print(samp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
